#Cargamos todos los paquetes que vamos a emplear, Keras dispone de diferentes paquetes para cada una de las herrmientas de CNN:

from keras.models import Sequential
from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate
from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.layers.pooling import MaxPooling2D, AveragePooling2D
from keras.layers.merge import Concatenate
from keras.layers.core import Lambda, Flatten, Dense
from keras.initializers import glorot_uniform
from keras.engine.topology import Layer
from keras import backend as K
K.set_image_data_format('channels_first')
import cv2
import os
import numpy as np
from numpy import genfromtxt
import pandas as pd
import tensorflow as tf
from fr_utils import *
from inception_blocks_v2 import *

#Pasamos ahora al cálculo de la función de triple pérdida
def triplet_loss(y_true, y_pred, alpha = 0.2):
   
   #Definimos la clase de prueba, la positiva y la negativa como se ha explicado en el trabajo
    
    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
    
   
   
    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)
    
    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)
    
    basic_loss = pos_dist - neg_dist + alpha
  
    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))
   
    
    return loss
    
    #Cargamos nuestra Inception network ya entrenada para nuestro modelo particular
    FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])
    load_weights_from_FaceNet(FRmodel)
    
    #Creammos la base de datos con las personas que van a ser autorizadas
    
database = {}
database["danielle"] = img_to_encoding("images/danielle.png", FRmodel)
database["younes"] = img_to_encoding("images/younes.jpg", FRmodel)
database["tian"] = img_to_encoding("images/tian.jpg", FRmodel)
database["andrew"] = img_to_encoding("images/andrew.jpg", FRmodel)
database["kian"] = img_to_encoding("images/kian.jpg", FRmodel)
database["dan"] = img_to_encoding("images/dan.jpg", FRmodel)
database["sebastiano"] = img_to_encoding("images/sebastiano.jpg", FRmodel)
database["bertrand"] = img_to_encoding("images/bertrand.jpg", FRmodel)
database["kevin"] = img_to_encoding("images/kevin.jpg", FRmodel)
database["felix"] = img_to_encoding("images/felix.jpg", FRmodel)
database["benoit"] = img_to_encoding("images/benoit.jpg", FRmodel)
database["arnaud"] = img_to_encoding("images/arnaud.jpg", FRmodel)

#Creamos ahora la funcion que aplique VERIFICACION FACIAL, como primer control identitario

def verify(image_path, identity, database, model):
  
 
    encoding = img_to_encoding(image_path, model)

    dist = np.linalg.norm(encoding-database[identity])
    
  
    if dist < 0.7:
        print("It's " + str(identity) + ", welcome home!")
        door_open = True
    else:
        print("It's not " + str(identity) + ", please go away")
        door_open = False
        
        
    return dist, door_open


#Por si la verificacion de identidad pasa por alto personas con identidades falsas, implantemos un sistemas de reconocimiento facial
#Vemos si la foto de cada una de las personas que quieren tener acceso tiene una distancia menor a una que fijamos previamente en la siguiente
#funcion para ver si es alguna de las personas de nuestro base de datos

def who_is_it(image_path, database, model):
    
    
    encoding = img_to_encoding(image_path, model)
    
    
    
    min_dist = 100
    
   
    for (name, db_enc) in database.items():
        
        
        dist = np.linalg.norm(encoding-database[name])

       
        if dist < min_dist:
            min_dist = dist
            identity = name
    
    if min_dist > 0.7:
        print("Not in the database.")
    else:
        print ("it's " + str(identity) + ", the distance is " + str(min_dist))
        
    return min_dist, identity
    
    
    #Aplicamos el modelo con una imagen cualquiera
    
    who_is_it("images/camera_0.jpg", database, FRmodel)
